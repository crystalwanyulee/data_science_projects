{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.linalg as scipy_linalg\n",
    "from collections import defaultdict \n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "\n",
    "#os.chdir('C://Users/wanyu/Documents/Computational Linguilistics/PA5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSWC():\n",
    "    \n",
    "    def __init__(self, word_dict=None, ppmi_matrix=None):\n",
    "        self.word_dict = word_dict\n",
    "        self.freq_matrix = None\n",
    "        self.ppmi_matrix = ppmi_matrix\n",
    "        self.V = None    \n",
    "\n",
    "        \n",
    "    def PPMI(self, sentences):\n",
    "        \n",
    "        # Create a word dictionary\n",
    "        words = []\n",
    "        for sentence in sentences:\n",
    "            words.extend(sentence)\n",
    "        \n",
    "        words = list(set(words))\n",
    "        self.word_dict = {word: index for index, word in enumerate(words)}\n",
    "        \n",
    "        # Creating a co-occurence matrix\n",
    "        self.freq_matrix = np.zeros((len(words), len(words)))\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            for index, word in enumerate(sentence):\n",
    "                if index != 0: \n",
    "                    context_idx = self.word_dict[sentence[index-1]]\n",
    "                    word_idx = self.word_dict[word]\n",
    "                    self.freq_matrix[word_idx, context_idx] += 1\n",
    "\n",
    "        # Repeating sentnences and Smoothing counts            \n",
    "        self.freq_matrix = self.freq_matrix*10 + 1\n",
    "\n",
    "        total = self.freq_matrix.sum().sum()\n",
    "        \n",
    "        # Computing PPMI\n",
    "        join_prob = self.freq_matrix/total\n",
    "        word_prob = self.freq_matrix.sum(axis=1)/total\n",
    "        context_prob = self.freq_matrix.sum(axis=0)/total\n",
    "        \n",
    "        independent_prob = (word_prob[:,None]*context_prob).T\n",
    "        self.ppmi_matrix = np.log(join_prob*(1/independent_prob))\n",
    "        \n",
    "        self.ppmi_matrix = np.maximum(self.ppmi_matrix, np.zeros((len(self.word_dict), len(self.word_dict))))\n",
    "\n",
    "    def SVD(self):\n",
    "        U, E, Vt = scipy_linalg.svd(self.ppmi_matrix, full_matrices=False)\n",
    "        U = np.matrix(U) # compute U\n",
    "        E = np.matrix(np.diag(E)) # compute E\n",
    "        Vt = np.matrix(Vt) # compute Vt = conjugage transpose of V\n",
    "        \n",
    "        return Vt.T # compute V = conjugate transpose of Vt\n",
    "    \n",
    "    def reduced_PPMI(self, dimension):\n",
    "        self.V = self.SVD()\n",
    "        reduced_PPMI = self.ppmi_matrix * self.V[:, 0:dimension]\n",
    "        \n",
    "        return reduced_PPMI\n",
    "    \n",
    "    def word_vector(self, words, word_matrix=None):\n",
    "        '''\n",
    "        Get a word vector based on the default matrix\n",
    "        '''\n",
    "        \n",
    "        if word_matrix is None:\n",
    "            word_matrix = self.ppmi_matrix                  \n",
    "        \n",
    "        if type(words) == list:\n",
    "            word_index = [self.word_dict[word] for word in words]\n",
    "            word_vector = word_matrix[word_index].astype('float')\n",
    "            \n",
    "        else: \n",
    "             word_index = self.word_dict[words]\n",
    "        \n",
    "        word_vector = word_matrix[word_index]\n",
    "        \n",
    "        return word_vector\n",
    "    \n",
    "    \n",
    "    def euclidean(self, word1, word2, word_matrix=None, v_input=False):\n",
    "        \n",
    "        '''\n",
    "        Compute the Euclidean distance between two vectors\n",
    "        '''\n",
    "        \n",
    "        if word_matrix is None:\n",
    "            word_matrix = self.ppmi_matrix   \n",
    "        \n",
    "        if v_input:\n",
    "            v1, v2 = word1, word2\n",
    "        \n",
    "        else:\n",
    "            v1 = self.word_vector(word1, word_matrix)\n",
    "            v2 = self.word_vector(word2, word_matrix)\n",
    "        \n",
    "        distance = scipy_linalg.norm(v2-v1)\n",
    "        \n",
    "        return distance\n",
    "    \n",
    "    def cosine_similarity(self, word1, word2, word_matrix=None, v_input=False):\n",
    "        '''\n",
    "        Compute the cosine similarity between two words or one word and several words\n",
    "        '''\n",
    "        \n",
    "        if word_matrix is None:\n",
    "            word_matrix = self.ppmi_matrix   \n",
    "        \n",
    "        if v_input:\n",
    "            v1, v2 = word1, word2\n",
    "        \n",
    "        else:\n",
    "            v1 = self.word_vector(word1, word_matrix)\n",
    "            v2 = self.word_vector(word2, word_matrix)\n",
    "            \n",
    "        length_v1 = scipy_linalg.norm(v1)\n",
    "        length_v2 = scipy_linalg.norm(v2, axis=1)\n",
    "        denominator = length_v1 * length_v2\n",
    "        numerator = np.squeeze(np.asarray(v1.dot(v2.T)))\n",
    "        similarity = numerator*(1/denominator)\n",
    "        \n",
    "        return similarity  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create distributional semantic word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files\n",
    "with open('dist_sim_data.txt') as f:\n",
    "    sentences = f.read().splitlines()\n",
    "    sentences = [sentence.split() for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dswc = DSWC()        \n",
    "dswc.PPMI(sentences)\n",
    "\n",
    "dogs = pd.DataFrame({'Raw Counts': dswc.word_vector('dogs', dswc.freq_matrix).ravel(), \n",
    "                   'PPMI': dswc.word_vector('dogs').ravel()}, index=list(dswc.word_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>men</th>\n",
       "      <th>like</th>\n",
       "      <th>dogs</th>\n",
       "      <th>feed</th>\n",
       "      <th>bite</th>\n",
       "      <th>the</th>\n",
       "      <th>women</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw Counts</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPMI</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            men  like  dogs  feed  bite    the  women\n",
       "Raw Counts  1.0   1.0   1.0   1.0   1.0  91.00    1.0\n",
       "PPMI        0.0   0.0   0.0   0.0   0.0   2.09    0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs.T.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_original,sim_reduced = [], []\n",
    "pairs = [['women','men'],['women','dogs'],['men','dogs'],\n",
    "         ['feed','like'],['feed','bite'], ['like','bite']]\n",
    "reduced_PPMI = dswc.reduced_PPMI(3)\n",
    "\n",
    "for pair in pairs:\n",
    "    original = round(float(dswc.euclidean(pair[0], pair[1])),4)\n",
    "    reduced = round(float(dswc.euclidean(pair[0], pair[1], reduced_PPMI)),4)\n",
    "    sim_original.append(original)\n",
    "    sim_reduced.append(reduced)\n",
    "    \n",
    "pairs_text = ['_'.join(pair) for pair in pairs]\n",
    "distance = pd.DataFrame({'pairs':pairs_text, 'compact PPMI': sim_original,\n",
    "                          'reduced PPMI': sim_reduced})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compact PPMI</th>\n",
       "      <th>reduced PPMI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairs</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>women_men</th>\n",
       "      <td>0.2234</td>\n",
       "      <td>0.2234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women_dogs</th>\n",
       "      <td>0.3398</td>\n",
       "      <td>0.3398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>men_dogs</th>\n",
       "      <td>0.1164</td>\n",
       "      <td>0.1164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feed_like</th>\n",
       "      <td>0.6674</td>\n",
       "      <td>0.5220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feed_bite</th>\n",
       "      <td>2.1746</td>\n",
       "      <td>2.1701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like_bite</th>\n",
       "      <td>1.7205</td>\n",
       "      <td>1.6985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            compact PPMI  reduced PPMI\n",
       "pairs                                 \n",
       "women_men         0.2234        0.2234\n",
       "women_dogs        0.3398        0.3398\n",
       "men_dogs          0.1164        0.1164\n",
       "feed_like         0.6674        0.5220\n",
       "feed_bite         2.1746        2.1701\n",
       "like_bite         1.7205        1.6985"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.set_index('pairs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Synonym Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classic and google word vectors\n",
    "google_dict, classic_dict = defaultdict(int), defaultdict(int)\n",
    "\n",
    "with open('EN-wform.w.2.ppmi.svd.500.rcv_vocab.txt') as f:\n",
    "    classic_list = f.read().splitlines()\n",
    "    \n",
    "for index, vector in enumerate(classic_list):\n",
    "    word_vector = vector.split(' ')\n",
    "    classic_dict[word_vector[0]] = len(classic_dict)\n",
    "    classic_list[index] = word_vector[1:]\n",
    "\n",
    "with open('GoogleNews-vectors-rcv_vocab.txt') as f:\n",
    "    google_list = f.read().splitlines()\n",
    "\n",
    "for index, vector in enumerate(google_list):\n",
    "    word_vector = vector.split(' ')\n",
    "    google_dict[word_vector[0]] = len(google_dict)\n",
    "    google_list[index] = word_vector[1:]\n",
    "\n",
    "# Transform lists to matrices\n",
    "classic_matrix = np.matrix(classic_list).astype('float')\n",
    "google_matrix = np.matrix(google_list).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define google matrix and classic matrix\n",
    "google = DSWC(google_dict, google_matrix)\n",
    "classic = DSWC(classic_dict, classic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import synonym questions\n",
    "questions = json.load(open(\"synonyms_questions.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use google matrix and classic matrix to answer a synonym for each question\n",
    "accuracy_synonyms = [0] * 4\n",
    "\n",
    "for index, values in questions.items():   \n",
    "    sim_google = google.cosine_similarity(values['question'], values['choice'])\n",
    "    sim_classic = classic.cosine_similarity(values['question'], values['choice'])\n",
    "    dist_google = google.euclidean(values['question'], values['choice'])\n",
    "    dist_classic = classic.euclidean(values['question'], values['choice'])\n",
    "    ans_list = [sim_google.argmax(), sim_classic.argmax(), dist_classic.argmin(), dist_classic.argmin()]\n",
    "    for index, ans in enumerate(ans_list):\n",
    "        if ans == 0:\n",
    "            accuracy_synonyms[index] += 1\n",
    "            \n",
    "synonyms_detections =  pd.DataFrame(accuracy_synonyms, columns=['Accuracy'],\n",
    "                                    index=['cos_google', 'cos_classic', 'dist_google', 'dist_classic'])/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cos_google</th>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_classic</th>\n",
       "      <td>0.537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist_google</th>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist_classic</th>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Accuracy\n",
       "cos_google       0.627\n",
       "cos_classic      0.537\n",
       "dist_google      1.000\n",
       "dist_classic     1.000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms_detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SAT Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SAT questions\n",
    "answer_dict = {answer: index for index, answer in enumerate(['a','b','c','d','e'])}\n",
    "sat_questions = defaultdict(dict)\n",
    "with open('SAT-package-V3.txt') as f:\n",
    "    sat = f.readlines()[42:]\n",
    "    \n",
    "for i in range(1,3364,9):\n",
    "    index = len(sat_questions)\n",
    "    sat_questions[index]['question'] = re.findall(r'[^\\W]+', sat[i])[:2]\n",
    "    choice_list = []\n",
    "    for choice in sat[(i+1):(i+6)]:\n",
    "        choice_list.append(re.findall(r'[^\\W]+',  choice)[:2])\n",
    "    sat_questions[index]['choice'] = choice_list\n",
    "    sat_questions[index]['answer'] = answer_dict[sat[i+6][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to summarize the relation between two words\n",
    "def vec_summary(v1, v2, mode):\n",
    "    if mode == 0:\n",
    "        vec = v1+v2\n",
    "    elif mode == 1:\n",
    "        vec = v1-v2\n",
    "    elif mode == 2:\n",
    "        vec = np.multiply(v1,v2)\n",
    "    elif mode == 3:\n",
    "        vec = np.multiply(v1,1/v2)\n",
    "    elif mode == 4:\n",
    "        vec = np.concatenate((v1,v2),axis=1)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wanyu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: RuntimeWarning: divide by zero encountered in true_divide\n",
      "C:\\Users\\wanyu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "# Use cosine similarity to measure similarity\n",
    "results = {'Classic':[], 'Google':[]}\n",
    "for m in range(5):\n",
    "    accuracy_list_google = np.array([])\n",
    "    accuracy_list_classic = np.array([])\n",
    "\n",
    "    for index, values in sat_questions.items():\n",
    "        w1, w2 = values['question']\n",
    "        q1 = vec_summary(classic.word_vector(w1),classic.word_vector(w2),m)\n",
    "        q2 = vec_summary(google.word_vector(w1),google.word_vector(w2),m)\n",
    "        sim_list_classic, sim_list_google = np.array([]), np.array([])\n",
    "        for choice in values['choice']:\n",
    "            w1, w2 = choice\n",
    "            c1 = vec_summary(classic.word_vector(w1), classic.word_vector(w2),m)\n",
    "            c2 = vec_summary(google.word_vector(w1), google.word_vector(w2),m)\n",
    "            sim_list_classic = np.append(sim_list_classic, classic.cosine_similarity(q1,c1,v_input=True))\n",
    "            sim_list_google = np.append(sim_list_google, google.cosine_similarity(q2,c2,v_input=True))\n",
    "\n",
    "\n",
    "        accuracy_list_classic= np.append(accuracy_list_classic, sim_list_classic.argmax() == values['answer'])\n",
    "        accuracy_list_google= np.append(accuracy_list_classic, sim_list_google.argmax() == values['answer'])\n",
    "\n",
    "\n",
    "    results['Classic'].append(accuracy_list_classic.mean().round(4))\n",
    "    results['Google'].append(accuracy_list_google.mean().round(4))\n",
    "\n",
    "sat_cos = pd.DataFrame(results, index=['Addition', 'Subtraction', 'Multiplication', 'Division', 'Concatenation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Euclidean Distance to measure similarity\n",
    "results = {'Classic':[], 'Google':[]}\n",
    "for m in range(5):\n",
    "    accuracy_list_google = np.array([])\n",
    "    accuracy_list_classic = np.array([])\n",
    "\n",
    "    for index, values in sat_questions.items():\n",
    "        w1, w2 = values['question']\n",
    "        q1 = vec_summary(classic.word_vector(w1),classic.word_vector(w2),m)\n",
    "        q2 = vec_summary(google.word_vector(w1),google.word_vector(w2),m)\n",
    "        sim_list_classic, sim_list_google = np.array([]), np.array([])\n",
    "        for choice in values['choice']:\n",
    "            w1, w2 = choice\n",
    "            c1 = vec_summary(classic.word_vector(w1), classic.word_vector(w2),m)\n",
    "            c2 = vec_summary(google.word_vector(w1), google.word_vector(w2),m)\n",
    "            sim_list_classic = np.append(sim_list_classic, classic.euclidean(q1,c1,v_input=True))\n",
    "            sim_list_google = np.append(sim_list_google, google.euclidean(q2,c2,v_input=True))\n",
    "\n",
    "\n",
    "        accuracy_list_classic= np.append(accuracy_list_classic, sim_list_classic.argmin() == values['answer'])\n",
    "        accuracy_list_google= np.append(accuracy_list_classic, sim_list_google.argmin() == values['answer'])\n",
    "\n",
    "\n",
    "    results['Classic'].append(accuracy_list_classic.mean().round(4))\n",
    "    results['Google'].append(accuracy_list_google.mean().round(4))\n",
    "sat_dist = pd.DataFrame(results, index=['Addition', 'Subtraction', 'Multiplication', 'Division', 'Concatenation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classic</th>\n",
       "      <th>Google</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Addition</th>\n",
       "      <td>0.3102</td>\n",
       "      <td>0.3120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtraction</th>\n",
       "      <td>0.3824</td>\n",
       "      <td>0.3840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multiplication</th>\n",
       "      <td>0.2594</td>\n",
       "      <td>0.2587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Division</th>\n",
       "      <td>0.2032</td>\n",
       "      <td>0.2053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Concatenation</th>\n",
       "      <td>0.3904</td>\n",
       "      <td>0.3920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Classic  Google\n",
       "Addition         0.3102  0.3120\n",
       "Subtraction      0.3824  0.3840\n",
       "Multiplication   0.2594  0.2587\n",
       "Division         0.2032  0.2053\n",
       "Concatenation    0.3904  0.3920"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Aggregation Method</th>\n",
       "      <th>Division</th>\n",
       "      <th>Multiplication</th>\n",
       "      <th>Addition</th>\n",
       "      <th>Concatenation</th>\n",
       "      <th>Subtraction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Similarity</th>\n",
       "      <th>Word Matrix</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Cosine Similarity</th>\n",
       "      <th>Classic</th>\n",
       "      <td>0.1818</td>\n",
       "      <td>0.2353</td>\n",
       "      <td>0.3235</td>\n",
       "      <td>0.3904</td>\n",
       "      <td>0.4225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>0.1813</td>\n",
       "      <td>0.2373</td>\n",
       "      <td>0.3253</td>\n",
       "      <td>0.3920</td>\n",
       "      <td>0.4213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Euclidean Distance</th>\n",
       "      <th>Classic</th>\n",
       "      <td>0.2032</td>\n",
       "      <td>0.2594</td>\n",
       "      <td>0.3102</td>\n",
       "      <td>0.3904</td>\n",
       "      <td>0.3824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>0.2053</td>\n",
       "      <td>0.2587</td>\n",
       "      <td>0.3120</td>\n",
       "      <td>0.3920</td>\n",
       "      <td>0.3840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy                                        \\\n",
       "Aggregation Method             Division Multiplication Addition Concatenation   \n",
       "Similarity         Word Matrix                                                  \n",
       "Cosine Similarity  Classic       0.1818         0.2353   0.3235        0.3904   \n",
       "                   Google        0.1813         0.2373   0.3253        0.3920   \n",
       "Euclidean Distance Classic       0.2032         0.2594   0.3102        0.3904   \n",
       "                   Google        0.2053         0.2587   0.3120        0.3920   \n",
       "\n",
       "                                            \n",
       "Aggregation Method             Subtraction  \n",
       "Similarity         Word Matrix              \n",
       "Cosine Similarity  Classic          0.4225  \n",
       "                   Google           0.4213  \n",
       "Euclidean Distance Classic          0.3824  \n",
       "                   Google           0.3840  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the results into a table and compare them\n",
    "sat_dist['Similarity'] = 'Euclidean Distance'\n",
    "sat_cos['Similarity'] = 'Cosine Similarity'\n",
    "sat_comparison = pd.concat([sat_dist, sat_cos]).reset_index().rename(columns={'index':'Aggregation Method'})\n",
    "\n",
    "sat_comparison = pd.melt(sat_comparison, id_vars=['Similarity','Aggregation Method'], value_vars=['Classic', 'Google'], var_name='Word Matrix', value_name='Accuracy')\n",
    "#sat_comparison.iloc[:, [2,3,0,1,4]]\n",
    "#sat_comparison.groupby(['method','word_matrix','index']).mean().unstack(level=2)\n",
    "sat_comparison = pd.pivot_table(sat_comparison, index=['Similarity','Word Matrix'], columns='Aggregation Method', aggfunc=np.mean)\n",
    "sat_comparison.iloc[:,[2,3,0,1,4]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
